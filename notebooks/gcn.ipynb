{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDBi2u5Z6frb"
      },
      "source": [
        "⚠️ If you are mounting your google drive in Colab, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzcub5AxLJRi",
        "outputId": "dbdce383-33a0-4a4a-ead5-ee485fdef31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp /content/drive/MyDrive/FYP/FYP/test/output/data.npz ./output/data.npz\n",
        "# ! cp /content/drive/MyDrive/FYP/FYP/test/output/labels.npy ./output/labels.npy\n",
        "! cp /content/drive/MyDrive/FYP/FYP/test/output/train_idx.npy ./output/train_idx.npy\n",
        "! cp /content/drive/MyDrive/FYP/FYP/test/output/test_idx.npy ./output/test_idx.npy"
      ],
      "metadata": {
        "id": "0_oYiwalm4Od"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JvHycy3aFYiR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ws_lKFySHaIo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv = torch.__version__\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-\"$tv\".html\n",
        "!pip install torch-summary\n",
        "!pip install biopython"
      ],
      "metadata": {
        "id": "QsOS-bg-HYcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803c4b23-fed4-45b6-a559-4120afc72f7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt22cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt22cu121)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt22cu121)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt22cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.83)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.data import NeighborSampler\n",
        "import torch_geometric.transforms as T\n",
        "from torch_cluster import random_walk\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from Bio import SeqIO\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Wp7pqfHCHkK2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_path = f\"output\"\n",
        "result_path"
      ],
      "metadata": {
        "id": "7EwRoecgKlgO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e53e2609-960e-4f0c-b5fd-0cd198d75da5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(result_path)"
      ],
      "metadata": {
        "id": "FFTiLyP2F77_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9253c32e-ef36-4281-cfc0-9e54c0877114"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data.npz',\n",
              " 'model.pkl',\n",
              " 'train_idx.npy',\n",
              " 'ground_truth.txt',\n",
              " 'sample_weights.npy',\n",
              " 'test_idx.npy',\n",
              " 'labels.npy',\n",
              " 'read_ids']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.load(f\"{result_path}/labels.npy\",allow_pickle=True)\n",
        "data = np.load(f'{result_path}/data.npz')"
      ],
      "metadata": {
        "id": "w1emOGQ8Fagm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = np.array(open(f\"{result_path}/ground_truth.txt\").read().strip().split(\"\\n\"))\n",
        "ground_truth.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecRl8FE8oIWB",
        "outputId": "11bf5e38-09b3-4aad-a1a6-0ea6b33aa3c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(179244,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = np.load(f\"{result_path}/sample_weights.npy\")\n",
        "sample_weights.shape"
      ],
      "metadata": {
        "id": "pyahBEdt2tg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc812ac0-e2d8-4b05-de56-ab10ea96c3d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(173603,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_maps(read_ids_file_path, truth):\n",
        "    reads_truth = {}\n",
        "    read_id_idx = {}\n",
        "    # global read_id_idx\n",
        "    with open(read_ids_file_path) as read_ids_file:\n",
        "        for t, rid in tqdm(zip(truth, read_ids_file)):\n",
        "            rid = rid.strip().split()[0][1:]\n",
        "            reads_truth[rid] = t\n",
        "            read_id_idx[rid] = len(read_id_idx)\n",
        "\n",
        "    return reads_truth, read_id_idx"
      ],
      "metadata": {
        "id": "ruWVia8Rdw1m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reads_truth, read_id_idx = get_idx_maps(f\"{result_path}/read_ids\", labels)"
      ],
      "metadata": {
        "id": "R-7C2__CeElA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07df37d0-feb0-4210-e64a-c4ba5f4f3b7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "179244it [00:00, 390646.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all(np.array(list(reads_truth.values())) == labels)"
      ],
      "metadata": {
        "id": "j9eaACr4eLq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217272d9-4856-49a6-c557-f0c7e0962ba2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = data['edges']\n",
        "comp = data['scaled']"
      ],
      "metadata": {
        "id": "BdrVdcPVHFJn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp = torch.from_numpy(comp).float()"
      ],
      "metadata": {
        "id": "Mus5dmJdE4IC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = np.array(list(read_id_idx.items()))\n",
        "id_list"
      ],
      "metadata": {
        "id": "Vzp3G6n9bgYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db079086-283d-42ae-ac72-29cb1c468e05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['08628297-d792-4b1b-8d58-40e7232f28d0', '0'],\n",
              "       ['86fd9e27-f495-4b6e-8124-0c3dbdcd2c9b', '1'],\n",
              "       ['62cf08b0-4463-479f-b041-f4cdbaa1c3ed', '2'],\n",
              "       ...,\n",
              "       ['a6741036-5494-4df6-a42c-7174d639d50c', '179241'],\n",
              "       ['9a8fa5ea-bb75-44de-9789-4289e804c35f', '179242'],\n",
              "       ['95e17a7a-19aa-4018-8618-ef6c4dca75d8', '179243']], dtype='<U36')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges.shape"
      ],
      "metadata": {
        "id": "YPQ3f4G7pUhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ffe8cb-4028-4a35-d253-893bbfb97ab8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3412328, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "edge_index.shape"
      ],
      "metadata": {
        "id": "58YzLiDVaoUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8768fd43-6eb8-4067-9294-defbc97fd191"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3412328, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = np.load(f\"{result_path}/train_idx.npy\")\n",
        "test_idx = np.load(f\"{result_path}/test_idx.npy\")\n",
        "train_idx.shape, test_idx.shape"
      ],
      "metadata": {
        "id": "2x8eV39-p08W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e42f6b3-6d5b-4f2b-b888-658d2f32153e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((173603,), (5641,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data(truth, mask):\n",
        "    lb = LabelEncoder()\n",
        "    lb.fit(truth[mask])\n",
        "\n",
        "    y = np.full(len(truth), -1)\n",
        "\n",
        "    y[train_idx] = lb.transform(truth[train_idx])\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    no_classes = len(set(truth[train_idx]))\n",
        "\n",
        "    return y, no_classes, lb\n",
        "\n",
        "y, no_classes, encoder = get_train_data(labels, train_idx)"
      ],
      "metadata": {
        "id": "33Zq2O0SKxHr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_classes"
      ],
      "metadata": {
        "id": "Wxvfw_zmwvCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b997a1f0-3580-46e4-bd5a-50e62f1c8d7e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "328"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y[test_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK5hNQI1DFZA",
        "outputId": "88bdef57-142e-4cc5-9fef-e0694f7ae800"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y[train_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27riU-suC5XV",
        "outputId": "2c5911ce-af31-4ce1-a91d-bd8c046610e7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
              "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
              "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
              "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
              "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
              "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
              "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
              "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
              "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
              "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
              "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
              "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
              "       325, 326, 327])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, val_idx, weight_idx_train, weight_idx_val = train_test_split(train_idx, np.arange(len(train_idx)), test_size=0.1, random_state=42)\n",
        "train_idx.shape, val_idx.shape, weight_idx_train.shape, weight_idx_val.shape"
      ],
      "metadata": {
        "id": "xUdXuf2sqAh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f909a408-f3f9-4eb7-b86c-e93239c0932d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156242,), (17361,), (156242,), (17361,))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights_train = sample_weights[weight_idx_train]\n",
        "sample_weights_val = sample_weights[weight_idx_val]\n",
        "sample_weights_train.shape, sample_weights_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q37vYUtc250E",
        "outputId": "9a6f9bdc-4a7d-4375-fa02-0bfd9e8a8a0a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156242,), (17361,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_data(features, edges,y,train_idx,test_idx,val_idx):\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    train_indices = torch.tensor(train_idx, dtype=torch.long)\n",
        "    test_indices = torch.tensor(test_idx, dtype=torch.long)\n",
        "    val_indices = torch.tensor(val_idx, dtype=torch.long)\n",
        "\n",
        "    data = Data(x=features, edge_index=edge_index, y=y)\n",
        "\n",
        "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_indices] = True\n",
        "    test_mask[test_indices] = True\n",
        "    val_mask[val_indices] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.test_mask = test_mask\n",
        "    data.val_mask = val_mask\n",
        "\n",
        "\n",
        "    # split_ = T.RandomNodeSplit(num_val=0.1, num_test=0.2)\n",
        "    # data = split_(data)\n",
        "    # data = split_(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "data = get_graph_data(comp, edges,y,train_idx,test_idx,val_idx)"
      ],
      "metadata": {
        "id": "ngEBC72RHLex"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "7DXDVDVGPRpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635ae361-1701-41e0-f87e-631893bda231"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[179244, 136], edge_index=[2, 3412328], y=[179244], train_mask=[179244], test_mask=[179244], val_mask=[179244])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(model, graph):\n",
        "  model.eval()\n",
        "  pred = model(data).argmax(dim=1)\n",
        "  y_pred = encoder.inverse_transform(pred[data.test_mask].cpu())\n",
        "  y_true = ground_truth[test_idx]\n",
        "  mask_ = y_true != 'None'\n",
        "  y_pred = y_pred[mask_]\n",
        "  y_true = y_true[mask_]\n",
        "  correct = (y_pred == y_true).sum()\n",
        "  acc = int(correct) / int(mask_.sum())\n",
        "  return acc"
      ],
      "metadata": {
        "id": "5Jer92MmOUpg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_node_classifier(model, graph, optimizer, criterion, n_epochs=200):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(graph)\n",
        "        loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])\n",
        "        # print(loss)\n",
        "        weighted_train_loss = torch.mean(loss * torch.tensor(sample_weights_train))\n",
        "        weighted_train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = out.argmax(dim=1)\n",
        "        acc = eval_node_classifier(model, graph, graph.val_mask)\n",
        "\n",
        "        val_loss = criterion(out[graph.val_mask], graph.y[graph.val_mask])\n",
        "        weighted_val_loss = torch.mean(val_loss * torch.tensor(sample_weights_val))\n",
        "\n",
        "        train_losses.append(weighted_train_loss.item())\n",
        "        val_losses.append(weighted_val_loss.item())\n",
        "\n",
        "\n",
        "        weighted_train_loss_np = weighted_train_loss.detach().numpy()\n",
        "        weighted_val_loss_np = weighted_val_loss.detach().numpy()\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Train Loss: {weighted_train_loss_np:.4f}, Val Acc: {acc:.4f}, Val Loss: {weighted_val_loss_np:.4f}')\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(test_accuracy(model, graph))\n",
        "\n",
        "        if acc > 0.995:\n",
        "            break\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "\n",
        "def eval_node_classifier(model, graph, mask):\n",
        "    model.eval()\n",
        "    pred = model(graph).argmax(dim=1)\n",
        "    correct = (pred[mask] == graph.y[mask]).sum()\n",
        "    acc = int(correct) / int(mask.sum())\n",
        "    return acc"
      ],
      "metadata": {
        "id": "x8NGtBKsQDng"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_node_classifier(model, graph, optimizer, criterion, batch_size=128, n_epochs=200):\n",
        "#     train_losses = []\n",
        "#     val_losses = []\n",
        "\n",
        "#     for epoch in range(1, n_epochs + 1):\n",
        "#         model.train()\n",
        "#         epoch_train_loss = 0.0\n",
        "#         num_batches = len(graph.train_mask) // batch_size + 1\n",
        "\n",
        "#         for batch_start in range(0, len(graph.train_mask), batch_size):\n",
        "#             batch_end = min(batch_start + batch_size, len(graph.train_mask))\n",
        "#             batch_mask = graph.train_mask[batch_start:batch_end]\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             out = model(graph)\n",
        "#             print(out.shape)\n",
        "#             loss = criterion(out, graph.y[batch_mask])\n",
        "#             weighted_train_loss = torch.mean(loss * torch.tensor(sample_weights_train[batch_start:batch_end]))\n",
        "#             weighted_train_loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             epoch_train_loss += weighted_train_loss.item()\n",
        "\n",
        "#         train_losses.append(epoch_train_loss / num_batches)\n",
        "\n",
        "#         acc = eval_node_classifier(model, graph, graph.val_mask)\n",
        "#         val_loss = criterion(model(graph)[graph.val_mask], graph.y[graph.val_mask])\n",
        "#         weighted_val_loss = torch.mean(val_loss * torch.tensor(sample_weights_val))\n",
        "\n",
        "#         val_losses.append(weighted_val_loss.item())\n",
        "\n",
        "#         if epoch % 1 == 0:\n",
        "#             print(f'Epoch: {epoch:03d}, Train Loss: {train_losses[-1]:.4f}, Val Acc: {acc:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "#         if acc > 0.995:\n",
        "#             break\n",
        "\n",
        "#     return model, train_losses, val_losses\n",
        "\n",
        "\n",
        "# def eval_node_classifier(model, graph, mask):\n",
        "#     model.eval()\n",
        "#     pred = model(graph).argmax(dim=1)\n",
        "#     correct = (pred[mask] == graph.y[mask]).sum()\n",
        "#     acc = int(correct) / int(mask.sum())\n",
        "#     return acc"
      ],
      "metadata": {
        "id": "vPdQ4hIK9Vw1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_layers, device):\n",
        "        super(GNNModel,self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        # hidden_channels = (in_channels + out_channels)//2\n",
        "        hidden_channels = 128\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(hidden_channels, hidden_channels//2)\n",
        "        self.fc2 = torch.nn.Linear(hidden_channels//2, out_channels)\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = x.to(self.device)\n",
        "        edge_index = edge_index.to(self.device)\n",
        "\n",
        "        # print(x.shape, edge_index.shape)\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1aG964roHoSE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_layers = 2\n",
        "\n",
        "model = GNNModel(data.x.shape[1], no_classes, num_layers, device)"
      ],
      "metadata": {
        "id": "zghd6MlNH0Sd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=10e-6)"
      ],
      "metadata": {
        "id": "O1PJghqxItlX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_cVbcDSaKEQ",
        "outputId": "eeab12a3-2941-45de-e290-136ae473d90a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[179244, 136], edge_index=[2, 3412328], y=[179244], train_mask=[179244], test_mask=[179244], val_mask=[179244])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWuBEvsOq2N7",
        "outputId": "36516698-c7d4-42dc-90ed-d475eb1aa1e7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GNNModel(\n",
              "  (conv1): GCNConv(136, 128)\n",
              "  (conv2): GCNConv(128, 128)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=328, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_node_classifier(model, data, optimizer, criterion, n_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jFciJcdCZc2",
        "outputId": "2cb42e9c-537a-44c3-c965-8db3b36028f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Loss: 0.1320, Val Acc: 0.5888, Val Loss: 0.1315\n",
            "Epoch: 002, Train Loss: 0.1310, Val Acc: 0.5960, Val Loss: 0.1305\n",
            "Epoch: 003, Train Loss: 0.1296, Val Acc: 0.5949, Val Loss: 0.1298\n",
            "Epoch: 004, Train Loss: 0.1280, Val Acc: 0.5916, Val Loss: 0.1284\n",
            "Epoch: 005, Train Loss: 0.1272, Val Acc: 0.5986, Val Loss: 0.1266\n",
            "Epoch: 006, Train Loss: 0.1263, Val Acc: 0.6004, Val Loss: 0.1249\n",
            "Epoch: 007, Train Loss: 0.1254, Val Acc: 0.5980, Val Loss: 0.1248\n",
            "Epoch: 008, Train Loss: 0.1243, Val Acc: 0.6033, Val Loss: 0.1250\n",
            "Epoch: 009, Train Loss: 0.1236, Val Acc: 0.6026, Val Loss: 0.1220\n",
            "Epoch: 010, Train Loss: 0.1226, Val Acc: 0.6015, Val Loss: 0.1221\n",
            "0.11870120652945351\n",
            "Epoch: 011, Train Loss: 0.1221, Val Acc: 0.6061, Val Loss: 0.1224\n",
            "Epoch: 012, Train Loss: 0.1212, Val Acc: 0.6116, Val Loss: 0.1215\n",
            "Epoch: 013, Train Loss: 0.1201, Val Acc: 0.6090, Val Loss: 0.1198\n",
            "Epoch: 014, Train Loss: 0.1197, Val Acc: 0.6119, Val Loss: 0.1185\n",
            "Epoch: 015, Train Loss: 0.1187, Val Acc: 0.6148, Val Loss: 0.1194\n",
            "Epoch: 016, Train Loss: 0.1182, Val Acc: 0.6133, Val Loss: 0.1179\n",
            "Epoch: 017, Train Loss: 0.1176, Val Acc: 0.6123, Val Loss: 0.1170\n",
            "Epoch: 018, Train Loss: 0.1171, Val Acc: 0.6179, Val Loss: 0.1174\n",
            "Epoch: 019, Train Loss: 0.1169, Val Acc: 0.6147, Val Loss: 0.1170\n",
            "Epoch: 020, Train Loss: 0.1161, Val Acc: 0.6172, Val Loss: 0.1166\n",
            "0.11994322214336409\n",
            "Epoch: 021, Train Loss: 0.1151, Val Acc: 0.6189, Val Loss: 0.1148\n",
            "Epoch: 022, Train Loss: 0.1145, Val Acc: 0.6155, Val Loss: 0.1154\n",
            "Epoch: 023, Train Loss: 0.1142, Val Acc: 0.6185, Val Loss: 0.1146\n",
            "Epoch: 024, Train Loss: 0.1137, Val Acc: 0.6227, Val Loss: 0.1140\n",
            "Epoch: 025, Train Loss: 0.1131, Val Acc: 0.6163, Val Loss: 0.1133\n",
            "Epoch: 026, Train Loss: 0.1128, Val Acc: 0.6216, Val Loss: 0.1124\n",
            "Epoch: 027, Train Loss: 0.1119, Val Acc: 0.6270, Val Loss: 0.1115\n",
            "Epoch: 028, Train Loss: 0.1114, Val Acc: 0.6217, Val Loss: 0.1121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, f'{result_path}/model.pkl')"
      ],
      "metadata": {
        "id": "55gJhlyCDVW5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_losses(history[1], history[2])"
      ],
      "metadata": {
        "id": "hRrJgG0h9vm3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = eval_node_classifier(model, data, data.test_mask)\n",
        "print(f'Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "XHvOxQGGVQCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc930f9e-887e-4e88-c25a-59b4ec4f69af"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = model(data).argmax(dim=1)"
      ],
      "metadata": {
        "id": "pJ7076fqVXdB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred[data.test_mask], data.y[data.test_mask]"
      ],
      "metadata": {
        "id": "jjS_0LPFVrAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d8d318-15c3-48ca-a185-18be3eaac439"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 23,  95,  90,  ..., 269,  23,  23]),\n",
              " tensor([-1, -1, -1,  ..., -1, -1, -1]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.inverse_transform(pred[data.test_mask].cpu())"
      ],
      "metadata": {
        "id": "jeoSzuA9gBfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5127b64f-0dc1-4434-c8fe-2bac90a460b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bacillus spizizenii', 'Escherichia coli', 'Enterococcus faecalis',\n",
              "       ..., 'Staphylococcus aureus', 'Bacillus spizizenii',\n",
              "       'Bacillus spizizenii'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "l3pNi6LKN6O5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = ground_truth != 'None'"
      ],
      "metadata": {
        "id": "LILRD5VCPZHv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = ground_truth[test_idx]"
      ],
      "metadata": {
        "id": "rh1bPkIFxUIB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = encoder.inverse_transform(pred[data.test_mask].cpu())\n",
        "# y_true = encoder.inverse_transform(data.y[data.test_mask].cpu())"
      ],
      "metadata": {
        "id": "fY9pmhVshQni"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_ = y_true != 'None'\n",
        "y_pred = y_pred[mask_]\n",
        "y_true = y_true[mask_]"
      ],
      "metadata": {
        "id": "ec3grI2xOFMF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ7a0lq3haf2",
        "outputId": "06869535-1cca-4aa0-f61f-330246513708"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               precision    recall  f1-score   support\n",
            "\n",
            "          Bacillus spizizenii     0.1370    0.1598    0.1475       751\n",
            "      Cryptococcus neoformans     0.0000    0.0000    0.0000       130\n",
            "        Enterococcus faecalis     0.1026    0.4139    0.1644       604\n",
            "             Escherichia coli     0.1405    0.0990    0.1162       788\n",
            "Limosilactobacillus fermentum     0.0000    0.0000    0.0000       417\n",
            "       Listeria monocytogenes     1.0000    0.0014    0.0028       722\n",
            "       Pseudomonas aeruginosa     0.1140    0.0438    0.0633       707\n",
            "     Saccharomyces cerevisiae     0.0000    0.0000    0.0000       103\n",
            "          Salmonella enterica     0.1297    0.0917    0.1074       709\n",
            "        Staphylococcus aureus     0.1368    0.1929    0.1601       705\n",
            "\n",
            "                     accuracy                         0.1208      5636\n",
            "                    macro avg     0.1761    0.1002    0.0762      5636\n",
            "                 weighted avg     0.2247    0.1208    0.0954      5636\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeeTTLOoGP6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}