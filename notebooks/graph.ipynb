{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ4KU_QmvPz0"
      },
      "source": [
        "⚠️ If you are mounting your google drive in Colab, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1qodzdIjrZ_",
        "outputId": "daf8a3b4-2665-4310-ad92-f074fd5e00b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv-ikkM-vPz6",
        "outputId": "764a2263-e8d8-4ea6-c04b-f117e6f66040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "06e90I0svPz7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from  tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjS5GBKnS2Dm",
        "outputId": "34f87bf6-b2a5-48ff-faab-9aac6c0b1103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing install.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile install.sh\n",
        "current=$(pwd)\n",
        "\n",
        "# download boost\n",
        "wget https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz\n",
        "tar -xf boost_1_77_0.tar.gz\n",
        "\n",
        "# install boost\n",
        "cd boost_1_77_0\n",
        "\n",
        "./bootstrap.sh --with-libraries=program_options,iostreams\n",
        "./b2 install\n",
        "\n",
        "cd $current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F7BAmWs3TOKq"
      },
      "outputs": [],
      "source": [
        "!sh install.sh &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM7ZZcFpTRFZ",
        "outputId": "b2ce46d1-7550-4d7e-ebde-69fda5bfdb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing install-prereq.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile install-prereq.sh\n",
        "\n",
        "# install seqtk\n",
        "current=$(pwd)\n",
        "git clone https://github.com/lh3/seqtk.git;\n",
        "cd seqtk; make\n",
        "\n",
        "# install wtdbg2\n",
        "cd $current\n",
        "git clone https://github.com/ruanjue/wtdbg2\n",
        "cd wtdbg2 && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kTeEF3vFTT4O"
      },
      "outputs": [],
      "source": [
        "!sh install-prereq.sh &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/FYP/FYP/test/reads.fasta ./reads.fasta"
      ],
      "metadata": {
        "id": "w2TWMauHAJFd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wpyd2ZV4TVY_"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('output'): os.mkdir('output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BqLroXNPTueo"
      },
      "outputs": [],
      "source": [
        "exp = \"./output/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PftuveQ3Tyt4"
      },
      "outputs": [],
      "source": [
        "!grep \">\" ./reads.fasta > $exp/read_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7GNz8siVbjc",
        "outputId": "bb640395-9c8c-400a-98a9-8c898919d5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing filter_alignments.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile filter_alignments.py\n",
        "\n",
        "import sys\n",
        "import fileinput\n",
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "path = \"./\"\n",
        "\n",
        "if len(sys.argv) == 2:\n",
        "    path = sys.argv[1] + \"/\"\n",
        "\n",
        "class Alignment:\n",
        "    def __init__(self, line):\n",
        "        \"\"\"\n",
        "        COL1 qry_name\n",
        "        COL2 qry_strand\n",
        "        COL3 qry_length\n",
        "        COL4 qry_beg\n",
        "        COL5 qry_end\n",
        "        COL6 ref_name\n",
        "        COL7 ref_strand (always equals +)\n",
        "        COL8 ref_length\n",
        "        COL9 ref_beg\n",
        "        COL10 ref_end\n",
        "        COL11 match_len (length of matched k-mers)\n",
        "        COL12 align_len (length of aligned)\n",
        "        COL13 #kcnt (number of matched k-mers)\n",
        "        COL14 #gap (number of gapped BINs)\n",
        "        COL15 cigar (256 x SAM's cigar)\n",
        "        \"\"\"\n",
        "        data = line.strip().split(\"\\t\")\n",
        "        self.raw_data = line.strip()\n",
        "        self.qry_name = data[0]\n",
        "        self.qry_strand = data[1]\n",
        "        self.qry_length = int(data[2])\n",
        "        self.qry_beg = int(data[3])\n",
        "        self.qry_end = int(data[4])\n",
        "        self.ref_name = data[5]\n",
        "        self.ref_strand = data[6]\n",
        "        self.ref_length = int(data[7])\n",
        "        self.ref_beg = int(data[8])\n",
        "        self.ref_end = int(data[9])\n",
        "        self.match_len = int(data[10])\n",
        "        self.align_len = int(data[11])\n",
        "        self.kmers = int(data[12])\n",
        "        self.gap = int(data[13])\n",
        "\n",
        "\n",
        "def is_overlap(alignment):\n",
        "    qry_beg = alignment.qry_beg\n",
        "    qry_end = alignment.qry_end\n",
        "    ref_beg = alignment.ref_beg\n",
        "    ref_end = alignment.ref_end\n",
        "    qry_length = alignment.qry_length\n",
        "    ref_length = alignment.ref_length\n",
        "\n",
        "    THRESHOLD = 512\n",
        "\n",
        "    # full overlap\n",
        "    if qry_beg <= THRESHOLD and qry_length - qry_end <= THRESHOLD:\n",
        "        return True\n",
        "    elif ref_beg <= THRESHOLD and ref_length - ref_end <= THRESHOLD:\n",
        "        return True\n",
        "\n",
        "    # qry end overlap\n",
        "    if qry_length - qry_end <= THRESHOLD and ref_beg <= THRESHOLD:\n",
        "        return True\n",
        "    # ref end overlap\n",
        "    elif ref_length - ref_end <= THRESHOLD and qry_beg <= THRESHOLD:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def process_batch(alignments, fpe, fpd):\n",
        "    # skip alignments that are self, this can cause total failure\n",
        "    # skip non overlaps\n",
        "    alignments = [a for a in alignments if is_overlap(a) and a.qry_name!=a.ref_name]\n",
        "    # exit if empty (first scenario)\n",
        "    if len(alignments) == 0:\n",
        "        return\n",
        "\n",
        "    # compute alignment overlaps\n",
        "    alignments = sorted(alignments, key=lambda a: a.match_len, reverse=True)\n",
        "    match_lengths = [a.match_len for a in alignments]\n",
        "    mean_match = np.mean(match_lengths)\n",
        "\n",
        "    degree = 0\n",
        "    for n, a in enumerate(alignments):\n",
        "        # record actual edge count\n",
        "        degree += 1\n",
        "\n",
        "        # write only top 20 edges\n",
        "        if n < 20:\n",
        "            fpe.write(f\"{a.qry_name}\\t{a.ref_name}\\n\")\n",
        "\n",
        "    fpd.write(f\"{alignments[0].qry_name}\\t{degree}\\n\")\n",
        "\n",
        "active_query = None\n",
        "alns_buffer = []\n",
        "out_file_edges = open(path + 'reads.alns', 'w+')\n",
        "out_file_degree = open(path + 'degree', 'w+')\n",
        "\n",
        "for line in fileinput.input('-'):\n",
        "    if len(line.strip()) == 1:\n",
        "        continue\n",
        "\n",
        "    alignment = Alignment(line)\n",
        "\n",
        "    if alignment.qry_name != active_query:\n",
        "        # new query\n",
        "        # if there is a previous query process it\n",
        "        if len(alns_buffer) > 0:\n",
        "            process_batch(alns_buffer, out_file_edges, out_file_degree)\n",
        "            # sys.exit(0)\n",
        "\n",
        "        # reset buffers\n",
        "        active_query = alignment.qry_name\n",
        "        alns_buffer = [alignment]\n",
        "    else:\n",
        "        alns_buffer.append(alignment)\n",
        "\n",
        "if len(alns_buffer) > 0:\n",
        "    process_batch(alns_buffer, out_file_edges, out_file_degree)\n",
        "\n",
        "out_file_edges.close()\n",
        "out_file_degree.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxrAZlIcWDZe",
        "outputId": "5938cd34-9f1f-4f43-fc5e-8b8da9e75174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "-- total memory       13290472.0 kB\n",
            "-- available          11680824.0 kB\n",
            "-- 2 cores\n",
            "-- Starting program: ./wtdbg2/kbm2 -i ./reads.fasta -d ./reads.fasta -n 2000 -l 2560 -t 16\n",
            "-- pid                     52262\n",
            "-- date         Sat Apr 13 15:11:41 2024\n",
            "--\n",
            "[Sat Apr 13 15:11:41 2024] loading sequences\n",
            "179244 reads\n",
            "[Sat Apr 13 15:12:06 2024] Done, 179244 reads, 3734858266 bp, 14499904 bins\n",
            "[Sat Apr 13 15:12:06 2024] indexing, 16 threads\n",
            "[Sat Apr 13 15:12:06 2024] - scanning kmers (K0P21S4.00) from 14499904 bins\n",
            "14499904 bins\n",
            "** PROC_STAT(0) **: real 414.842 sec, user 451.990 sec, sys 24.480 sec, maxrss 5174616.0 kB, maxvsize 6427924.0 kB\n",
            "[Sat Apr 13 15:18:36 2024] - high frequency kmer depth is set to 1000\n",
            "[Sat Apr 13 15:18:38 2024] - Total kmers = 205083239\n",
            "[Sat Apr 13 15:18:38 2024] - average kmer depth = 2\n",
            "[Sat Apr 13 15:18:38 2024] - 0 low frequency kmers (<1)\n",
            "[Sat Apr 13 15:18:38 2024] - 527 high frequency kmers (>1000)\n",
            "[Sat Apr 13 15:18:38 2024] - indexing 205082712 kmers, 593583939 instances (at most)\n",
            "14499904 bins\n",
            "[Sat Apr 13 15:25:51 2024] - indexed  205082712 kmers, 593517224 instances\n",
            "[Sat Apr 13 15:25:51 2024] - masked 501 bins as closed\n",
            "[Sat Apr 13 15:25:51 2024] - sorting\n",
            "** PROC_STAT(0) **: real 861.966 sec, user 1072.250 sec, sys 49.330 sec, maxrss 8937256.0 kB, maxvsize 11782228.0 kB\n",
            "[Sat Apr 13 15:26:03 2024] mapping\n",
            "179244\t47388349\n",
            "[Sat Apr 13 20:10:14 2024] Done\n",
            "** PROC_STAT(TOTAL) **: real 17914.225 sec, user 23808.330 sec, sys 2116.900 sec, maxrss 9945124.0 kB, maxvsize 12592108.0 kB\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "!./wtdbg2/kbm2  -i ./reads.fasta -d ./reads.fasta -n 2000 -l 2560 -t 16 | python filter_alignments.py $exp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MRNqGqxB5ZlB"
      },
      "outputs": [],
      "source": [
        "exp = \"./output/\"\n",
        "\n",
        "alignments_file_path = exp + \"reads.alns\"\n",
        "degrees_file_path = exp + \"degree\"\n",
        "\n",
        "comp = pd.read_csv(exp + \"4-mers.tsv\", header=None).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsyAHCgsI_hY",
        "outputId": "01873348-11f9-49c5-cc0f-9636f6208c18"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(179244, 136)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugvqcAAqjWH5",
        "outputId": "4adaabd2-c1cb-464a-ea60-a3baba8f0881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179244\n"
          ]
        }
      ],
      "source": [
        "!grep -c '>' reads.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3rsyNefbOf79"
      },
      "outputs": [],
      "source": [
        "def get_idx_maps(read_ids_file_path):\n",
        "    read_id_idx = {}\n",
        "    # global read_id_idx\n",
        "    with open(read_ids_file_path) as read_ids_file:\n",
        "        for rid in tqdm(read_ids_file):\n",
        "            rid = rid.strip().split()[0][1:]\n",
        "            read_id_idx[rid] = len(read_id_idx)\n",
        "\n",
        "    return read_id_idx\n",
        "\n",
        "\n",
        "def load_read_degrees(degrees_file_path,read_id_idx):\n",
        "    degree_array = np.zeros((len(read_id_idx),), dtype=int)\n",
        "    for line in tqdm(open(degrees_file_path, 'r')):\n",
        "        i, d = line.strip().split()\n",
        "        d = int(d)\n",
        "        # print(degree_array)\n",
        "        degree_array[read_id_idx[i]] = d\n",
        "\n",
        "    return degree_array\n",
        "\n",
        "\n",
        "def load_edges_as_numpy(edges_txt_path, edges_npy_path):\n",
        "    if not os.path.isfile(edges_npy_path):\n",
        "        edges_txt = [x.strip() for x in tqdm(open(edges_txt_path))]\n",
        "        edges = np.zeros((len(edges_txt), 2), dtype=np.int32)\n",
        "\n",
        "        for i in tqdm(range(len(edges_txt))):\n",
        "            e1, e2 = edges_txt[i].strip().split()\n",
        "            edges[i]  = [int(e1), int(e2)]\n",
        "\n",
        "        np.save(edges_npy_path, edges)\n",
        "\n",
        "    return np.load(edges_npy_path)\n",
        "\n",
        "def alignments_to_edges(alignments_file_path, edges_txt_path, read_id_idx):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "\n",
        "    if not os.path.isfile(edges_txt_path):\n",
        "        with open(edges_txt_path, \"w+\") as ef:\n",
        "            for line in tqdm(open(alignments_file_path, \"r\")):\n",
        "                u, v = line.strip().split('\\t')\n",
        "\n",
        "                if u == v:\n",
        "                    continue\n",
        "                try:\n",
        "                    ef.write(f\"{read_id_idx[u]}\\t{read_id_idx[v]}\\n\")\n",
        "                except:\n",
        "                    print(f'Missing {u,v}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_2WU8qNOiL1",
        "outputId": "90000b9b-aef2-4b69-dfb3-26c384cb2047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "179244it [00:00, 322114.30it/s]\n",
            "177746it [00:00, 409992.40it/s]\n",
            "3412328it [00:12, 267815.36it/s]\n",
            "3412328it [00:01, 2023785.84it/s]\n",
            "100%|██████████| 3412328/3412328 [00:04<00:00, 753745.45it/s]\n"
          ]
        }
      ],
      "source": [
        "read_id_idx = get_idx_maps(exp + 'read_ids')\n",
        "degree_array = load_read_degrees(degrees_file_path,read_id_idx)\n",
        "alignments_to_edges(exp+\"reads.alns\", exp + \"edges.txt\", read_id_idx)\n",
        "\n",
        "edges = load_edges_as_numpy(exp + \"edges.txt\", exp + \"edges.npy\")\n",
        "sample_weights = np.zeros_like(degree_array, dtype=np.float32)\n",
        "sample_scale = np.ones_like(degree_array, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5IjDlKJDOn_j"
      },
      "outputs": [],
      "source": [
        "for n, d in enumerate(degree_array):\n",
        "    sample_weights[n] = 1.0/d if d>0 else 0\n",
        "    sample_scale[n] = max(1, np.log10(max(1, d)))\n",
        "\n",
        "scaled = comp * sample_scale.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cbLam1LKdAZT"
      },
      "outputs": [],
      "source": [
        "np.savez(exp + 'data.npz', edges=edges, scaled=scaled)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}